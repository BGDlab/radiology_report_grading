{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose of this notebook\n",
    "\n",
    "- Examine similarities and differences between different raters' reliability report grades\n",
    "- Calculate Cohen's kappa between pairs of raters\n",
    "- Identify and print reports where raters strongly disagree (grade of 2 vs grade of 0)\n",
    "\n",
    "## How to use this notebook\n",
    "\n",
    "- Run each of the cells in order. Make sure you run Cell 01 first.\n",
    "- Cell 02 can be used to see how many reports have been graded since a date (YYYY-MM-DD format)\n",
    "- Cells 03-04 get the proc_ord_id values unique to each report and the names of the persons who have graded reliability reports.\n",
    "- Cell 05 can be used to examine the reports a pair of graders disagree on\n",
    "- Cells 06 will release examined reports back to a specified grader for regrading\n",
    "- Cell 07 can be used to examine and regrade reports marked with a -1 flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 01: load libraries\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Add the code directory to sys.path\n",
    "sys.path.append(os.path.join(os.path.dirname(current_dir), 'code'))\n",
    "\n",
    "from reliabilityLib import *\n",
    "from reportMarkingFunctions import *\n",
    "from google.cloud import bigquery # SQL table interface on Arcus\n",
    "import pandas\n",
    "import numpy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "client = bigquery.Client()\n",
    "backup_grader_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grades Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 02:\n",
    "get_grade_counts_since(\"2024-10-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grader agreement on reliability reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 03: Get the list of proc_ord_id values used to identify the reliability reports\n",
    "procIds = get_reliability_proc_ord_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 04: Compare the reliability reports for the users we want to evaluate\n",
    "graders = ['Grader 1', \n",
    "           'Grader 2']\n",
    "\n",
    "# Metric options: \"disagreement\", \"kappa\", \"kappa2vAll\", \"kappa0vAll\"\n",
    "df = calculate_metric_for_graders(graders, \"kappa\")\n",
    "print()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 05: \n",
    "# This is the cell where you can look at the disagreement reports for each pair of users\n",
    "grader1 = \"Grader 1\"\n",
    "grader2 = \"Grader 2\"\n",
    "procIds = get_reliability_proc_ord_ids()\n",
    "grades1 = get_reports_for_user(grader1, procIds)\n",
    "grades2 = get_reports_for_user(grader2, procIds)\n",
    "disagreement = identify_disagreement_reports(grades1, grades2)\n",
    "print(len(disagreement))\n",
    "\n",
    "calc_kappa(grades1, grades2)\n",
    "\n",
    "print_disagreement_reports(disagreement, grades1, grades2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 06: release a set of your reports back into your queue \n",
    "# ONLY USE THIS IF YOU'RE CERTAIN\n",
    "# release_reports(grader2, disagreement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine flagged reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 07: regrade skipped reports\n",
    "# client: A bigquery client object (created in Cell 01)\n",
    "# skippedGrader: A string of the grader's name (leave blank to review all flagged reports)\n",
    "skippedGrader = \"Grader Name\"\n",
    "regrade_skipped_reports(client, grader=skippedGrader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For clinician review only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 08: clinician regrade skipped reports\n",
    "# client: A bigquery client object (created in Cell 01)\n",
    "# skippedGrader: A string of the grader's name (leave blank to review all flagged reports)\n",
    "regrade_skipped_reports(client, flag=-2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
